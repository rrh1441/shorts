# VO-Led Video Generator - Implementation Status

## Current Status: Rendering Fixed, Guardrails Tightened

âœ… Visual rendering now works across all scenes with sceneâ€‘relative reveals, baseline fallbacks, and provenance tags. Aspect is respected, and renders are gated by lints and word budgets.

### Changes Implemented â€” 2025â€‘09â€‘14
- Sceneâ€‘relative cues: Converted VO cues to scene offsets to fix invisible elements beyond scene 1.
- Reveal safety: Clamped reveal delays to scene duration to avoid neverâ€‘visible animations.
- Baseline visuals: Guaranteed at least one readable text element per scene when heuristics produce no visuals.
- Aspect propagation: Composition aspect inferred from dimensions and passed to primitives (safe areas + type scale).
- Lint gating: `render:videodoc` blocks when `lint-report.json` fails unless `--force` is provided.
- Word budgets enforced: `scripts/script.ts` now hardâ€‘fails when outside the target word range.
- Audio integration: `plan-new.ts` saves `vo.mp3`; `render:videodoc` autoâ€‘detects it if no audio path is provided.
- Provenance tags: Onâ€‘screen caption appears at the specified cue for each evidence item.
- Tokens API consistency: `getSafeArea(aspect)` signature aligned with usage.

### âœ… Pipeline Components Working
- **Content Ingestion**: `ingest` command parses content correctly
- **Narrative Synthesis**: `synthesize` generates story briefs  
- **VO Script Generation**: `script` creates word-budgeted scenes
- **Scene Planning**: `plan:new` produces VideoDoc JSON with timing
- **MP4 Rendering**: `render:videodoc` generates video files

### âœ… Visual Rendering
- All scenes render as expected with timed reveals.
- Charts/callouts/text appear with safe timing and readable defaults.
- Provenance captions appear at or after the cited cue.

### ðŸ§© Root Causes Resolved
1. Absolute VO cues used for perâ€‘scene reveals â†’ switched to sceneâ€‘relative cues.
2. Empty visual arrays in some scenes â†’ added baseline text fallback.
3. Aspect hardcoded to horizontal â†’ inferred from composition and applied to primitives.
4. No render gate on quality â†’ added lint and budget gates with `--force` override.

### ðŸ“‹ Test Results
```bash
npm run ingest test-content.md ./output     # âœ… Works
npm run synthesize                          # âœ… Works  
npm run script                              # âœ… Works
npm run plan:new                            # âœ… Works
npm run render:videodoc videoDoc.json video.mp4  # âœ… Renders with visuals
```

Notes:
- Provide `--aspect=horizontal|square|vertical` (aliases: 16:9, 1:1, 9:16) as needed.
- Renders will block if lints fail; use `--force` to override.

### ðŸš¨ PRIORITY FIXES NEEDED
1. **Debug VideoDoc.json**: Check if visual elements are actually generated in scene specs
2. **Fix Visual Element Rendering**: VDS primitives (Text, Callout, ChartFrame, Shape) not appearing
3. **Scene Timing Issues**: Investigate why only first scene shows content
4. **Remotion Integration**: Ensure VideoDoc â†’ JSX mapping works correctly
5. **Animation System**: Fix reveal timing so elements actually appear

### ðŸ“‚ Project Structure (Partially Implemented)
- `scripts/create-project.ts` - Project folder creation (untested)
- `scripts/project-generate.ts` - Project-based pipeline (untested)
- New commands: `npm run create:project`, `npm run project:generate`

**Status**: Project structure created but not tested due to rendering failures.

---

Below is the **comprehensive PRD** for the complete system transformation:

---

# Product Requirements Document (PRD)

**Product:** VOâ€‘Led Explainer & Clip Generator
**Owner:** \[You]
**Stakeholders:** Content/PMM, Demand Gen, Eng/ML, Design
**Goal:** Convert longâ€‘form source content (whitepapers, webinars/podcasts) into **highâ€‘polish, onâ€‘brand videos** and **short social clips**, optimized for attention and clarity. The **voiceover (VO) is the spine**; visuals support the story.
**Nonâ€‘Goal:** Faithfully reproducing the source document structure or slideware aesthetics.

---

## 1) Objectives & Success Metrics

**Primary objectives**

1. **Storyâ€‘first output:** VO determines scene order, length, and reveals; source order is advisory.
2. **High visual polish:** Video-first design primitives, theme packs, and motion grammar (Gammaâ€‘like quality without slideware).
3. **Shortâ€‘form formats:** Native support for **60â€“90s microâ€‘explainers** and **30s standâ€‘alone clips**.
4. **Deterministic corrections:** All edits as **JSON patches** (LLMâ€‘friendly), stable IDs, reproducible renders.

**Success metrics (quantitative)**

* **Time to first cut:** â‰¤ 5 minutes from ingest to first render for a 90s piece (cold cache, standard hardware).
* **Revision efficiency:** â‰¥ 90% of common changes expressed as JSON patches (no code changes).
* **Completion rate:** â‰¥ 80% of scenes pass automated **narrative + design lints** on first run.
* **Engagement proxy:** For shortâ€‘form, median watch time â‰¥ 60% of duration; for microâ€‘explainer, â‰¥ 50%.
* **Brand consistency:** 100% captioned, WCAG AA contrast, provenance tags on all cited stats.

---

## 2) Scope

**In scope**

* Content ingestion (PDFs, transcripts), narrative synthesis, VO script, VO timing, scene JSON generation, Remotion render, captions/SRT, multiâ€‘aspect outputs (16:9, 1:1, 9:16), provenance tags, preâ€‘render linters, JSONâ€‘patch corrections, shortâ€‘form templates.

**Out of scope (v1)**

* Advanced scene editor UI; multiâ€‘speaker lipâ€‘sync; automatic stock/Bâ€‘roll licensing flows.

---

## 3) Users & Jobs-to-be-Done

* **PMM/Founder:** Needs a 60â€“90s explainer for a launch; can accept resequencing if story improves.
* **Social/Content Marketer:** Needs 30s clips from podcasts/webinars that stand alone on feeds.
* **Sales Enablement:** Needs caseâ€‘led microâ€‘explainers with one clear proof and CTA.

---

## 4) System Overview

**Pipeline (topâ€‘level):**

1. **Ingest** â†’ 2. **Narrative Brief** â†’ 3. **VO Script (radio cut)** â†’ 4. **TTS + Word/Sentence Timestamps** â†’
2. **Scene JSON (story roles + cues)** â†’ 6. **Visual Plan (primitives + motion)** â†’ 7. **Lints** â†’ 8. **Render** â†’ 9. **Review & Patch**

**Design Architecture:**

* **Tokens (foundation):** Adopt shadcn **tokens** (colors/spacing/typography) but **do not** reuse app UI components.
* **Primitives (videoâ€‘first):** `Surface`, `Stack/HStack/Grid`, `Text`, `Media`, `Shape`, `Callout`, `ChartFrame`.
* **Motion grammar:** Standardized entrances/exits, easings, cadence, camera drift.
* **Theme packs:** `GradientGlass`, `MinimalEditorial`, `KineticType`, `ProductDemo`. Switchable without content changes.

---

## 5) Functional Requirements

### 5.1 Ingestion

* Accept **PDF whitepapers** and **webinar/podcast transcripts** (with speaker/time metadata if available).
* Extract structured chunks: headings, paragraphs, tables/figures (whitepaper); segments, diarization, quotables (transcript).
* Produce a **Provenance Ledger** with stable IDs (`provId`) for citeable items (stat/quote/figure).

**Acceptance**

* Given a 20â€‘page PDF, the system returns â‰¥ 90% of headings and paragraphs with order preserved and a ledger of references.
* Given a transcript with timestamps, segments retain original timestamps (Â±1s).

### 5.2 Narrative Synthesis (Storyâ€‘first)

* Generate a **Narrative Brief**:

  * `controllingIdea`, `audienceChange`, `antagonist`, `stakes`, `promise`, `proofPillars[â‰¤3]`, `nextStep`, `arc`.
* **Arcs supported:**

  * **Problem â†’ Turn â†’ Value/How â†’ Proof â†’ CTA** (default)
  * **Caseâ€‘led** (Outcome â†’ Backstory â†’ Intervention â†’ Result â†’ CTA)
  * **Monroeâ€™s Motivated Sequence** (optional, keep in schema)
* **Allow resequencing** irrespective of source order.

**Acceptance**

* Brief contains â‰¤ 1 sentence per field; â‰¤ 3 proof pillars; any uncited claim is labeled â€œobservationâ€.

### 5.3 VO Script (Radio Cut) & Timing

* Write VO **before** visuals; 105â€“120 wpm; average sentence length 16â€“20 words.
* Inject **evidence tokens** referencing `provId` inâ€‘line (e.g., `[prov:s1]`).
* Produce **sentenceâ€‘onset cues** (ms) via TTS or alignment.
* Enforce **word budgets**:

  * **30s clip:** 47â€“55 words; max 3 sentences/scene.
  * **60â€“90s micro:**

    * 60s: 95â€“110 words
    * 75s: 115â€“130 words
    * 90s: 140â€“160 words

**Acceptance**

* Overâ€‘budget scripts are rejected with a diff suggesting deletions until within budget.

### 5.4 Scene DSL (Data Model)

* Scenes have **story roles** and **voiceover cues**.
* Elements use **video primitives** only.

```ts
// Lint-clean TypeScript schema
export type Arc = 'ProblemTurnProof' | 'CaseLed' | 'MMS';

export interface StoryMeta {
  controllingIdea: string;
  arc: Arc;
  targetDurationSec: number;
  audience: string;
  allowResequence: true;
  provenance: { id: string; label: string; href?: string }[];
}

export type SceneRole =
  | 'HOOK' | 'PROBLEM' | 'TURN' | 'APPROACH' | 'PROCESS'
  | 'PROOF' | 'CASE' | 'QUOTE' | 'CTA' | 'OUTCOME' | 'BACKSTORY' | 'RESULT';

export interface Voiceover {
  text: string;        // full VO for the scene
  cues: number[];      // ms offsets for sentence starts
}

export type Element =
  | { kind: 'TEXT'; role: 'title'|'subtitle'|'body'|'caption'|'kicker'; text: string }
  | { kind: 'MEDIA'; src: string; fit?: 'cover'|'contain'; focalPoint?: { x: number; y: number }; mask?: 'rounded'|'device'|'circle'|'none' }
  | { kind: 'SHAPE'; shape: 'blob'|'bar'|'ring'|'underline'; seed?: number; opacity?: number; animate?: 'drift'|'pulse'|'wipe' }
  | { kind: 'CHART'; chart: 'bar'|'line'|'pie'|'metric'; data: unknown; emphasize?: number[] }
  | { kind: 'CALLOUT'; text: string };

export interface Scene {
  id: string;
  role: SceneRole;
  voiceover: Voiceover;
  visuals: Element[];
  evidence?: { provId: string; atCue: number }[]; // tie claims to on-screen moments
  motion?: 'standard'|'emphasis'|'gentle';
  accentColor?: string;
  durationMs?: number; // computed if omitted
}

export interface VideoDoc {
  story: StoryMeta;
  scenes: Scene[];
}
```

**Computation rule:** If `durationMs` missing, compute:

```
duration = clamp( words/target_wps*1000 + reveals*250 + 600 /*enter*/ + 350 /*exit*/, 2200, 6500 )
```

with `target_wps â‰ˆ 1.83`.

**Acceptance**

* JSON validates via Zod; IDs stable across revisions; patching a scene by `id` does not reorder others.

### 5.5 Video Design System (VDS)

* **Tokens:** color palette (brand, accent, neutrals), type scale per aspect ratio, spacing scale, radii, shadows, blur levels, opacity steps, **safe areas**.
* **Theme Packs:** `GradientGlass`, `MinimalEditorial`, `KineticType`, `ProductDemo`.
* **No app UI components.** Only primitives above.

**Acceptance**

* Switching theme pack changes **style** without changing `VideoDoc` content.

### 5.6 Motion Grammar

* **Entrances:** fade+Y (24â€“36px), maskâ€‘wipe, scaleâ€‘in (0.96â†’1.0) at 600â€“750ms.
* **Exits:** reverse; 250â€“350ms.
* **Easings:**

  * `standard`: cubicâ€‘bezier(0.2, 0.8, 0.2, 1)
  * `emphasis`: (0.12, 0.9, 0.1, 1)
  * `gentle`: spring (low stiffness, damping 26â€“30)
* **Camera drift:** 1.02â€“1.06 scale over scene; optional parallax on background layers.
* **Reveal cadence:** tie to `voiceover.cues` Â±120ms; â‰¤ 3 concurrent animations.

**Acceptance**

* Lint fails if > 3 concurrent animations or reveals not aligned within Â±200ms of cues.

### 5.7 Templates & Formats

* **Microâ€‘explainer (60/75/90s) templates:**

  * Arc A: Problem â†’ Turn â†’ Value/How â†’ Proof â†’ CTA
  * Arc B: Caseâ€‘led: Outcome â†’ Backstory â†’ Intervention â†’ Result â†’ CTA
* **30s clip templates:**

  * T1 Quote, T2 Mythâ†’Fact, T3 Numberâ†’Meaning, T4 Beforeâ†’After, T5 Qâ†’A.
* **Aspect presets:** 16:9, 1:1, 9:16 with adjusted safe areas and type scales.

**Acceptance**

* Rendering any template in all three aspects keeps text within safe areas; captions never collide with lower thirds.

### 5.8 Captions & Accessibility

* Burnedâ€‘in captions and exported `.srt`.
* Max 2 lines, â‰¤ 32 chars/line; line breaks at phrase boundaries.
* WCAG AA contrast for text overlays.

**Acceptance**

* Automated caption audit passes (length, contrast, collision).

### 5.9 Evidence & Provenance

* Onâ€‘screen **provenance tag** appears at or after `evidence.atCue`.
* Missing provenance downgrades the line from â€œstatâ€ to â€œobservationâ€ or fails lint (configurable).

**Acceptance**

* Every `[prov:...]` in VO has a matching onâ€‘screen tag; missing tags trigger lint failure.

### 5.10 Rendering & Performance

* Remotion renders from `VideoDoc` â†’ JSX mapping; **no Tailwind class churn at runtime** (precomputed tokens).
* Render queue supports **batch** (multiple aspect ratios per job).
* Caching of TTS audio and resolved assets by content hash.

**Acceptance**

* Cold render of a 60s microâ€‘explainer completes within an acceptable budget on standard hardware; subsequent renders with no content change are cache hits for TTS and assets.

### 5.11 Lints & QA Gates (Blocking)

* **Narrative:** HOOK present; TURN by â‰¤ 40% runtime; CTA present (micro) or explicit takeaway (30s).
* **Pacing:** No scene > 28s (micro) or > 20s (30s); mean scene â‰¤ 15s.
* **Clarity:** Fleschâ€‘Kincaid â‰¤ 9 (configurable by audience).
* **Design:** Contrast AA, safe areas; â‰¤ 1 accent color/scene; max concurrent animations â‰¤ 3.
* **Evidence:** All cited stats have provenance.
* **Captions:** Rules in Â§5.8.

**Acceptance**

* Renders are **blocked** when any lint fails; report enumerates violations with suggested fixes.

### 5.12 Podcast/Webinar Clip Extraction (30s)

* Compute **ClipScore** per segment:

```
ClipScore = 0.30*TurnDensity + 0.25*EvidencePresence + 0.20*SelfContainment
          + 0.15*ProsodyEnergy + 0.10*Memorability
```

* Reject if `SelfContainment < 0.6` or duration outside 24â€“33s.
* If no evidence, autoâ€‘insert **microâ€‘setup** line â‰¤ 10 words.

**Acceptance**

* Topâ€‘5 clips surfaced with filled template candidates (T1â€“T5) and VO within 47â€“55 words.

### 5.13 Corrections Flow (Deterministic)

* All edits as **RFC 6902 JSON Patch** against `VideoDoc`.
* Stable IDs; patches can target: VO text, cues, element text, data values, theme pack, accent color, timing offsets.

**Acceptance**

* Applying and reversing a patch yields identical renders (hashâ€‘stable audio and JSON).

### 5.14 Configuration & Theming

* **Env/config:** brand colors, logo, font families (variable fonts preferred), default arc, default template, aspect ratios to render, caption styles.
* **Token inheritance** from shadcn Tailwind config â†’ VDS tokens â†’ Theme packs.

**Acceptance**

* Changing brand primary color updates theme packs without scene JSON edits.

### 5.15 Telemetry & Observability

* Capture: ingest time, synthesis time, lint failures, render time, cache hits, error traces.
* Optional: postâ€‘publish engagement metrics ingestion (if available).

**Acceptance**

* Ops dashboard shows last 50 jobs with durations and failure reasons.

### 5.16 Security & Privacy

* Redact emails/API keys detected in source before VO/visuals.
* Configurable PII scrubber with allowâ€‘list for case studies.

**Acceptance**

* Any detected secret/PII is masked; lints fail if PII remains.

---

## 6) Nonâ€‘Functional Requirements

* **Determinism:** Same `VideoDoc` + assets + theme â†’ bitâ€‘identical audio and JSON outputs.
* **Composability:** New theme packs and templates can be added with no changes to the DSL.
* **Portability:** Headless rendering usable via CLI/CI.

---

## 7) API/CLI (Minimal)

**CLI Targets**

* `ingest <path>` â†’ `ingest.json` + `provenance.json`
* `synthesize --arc ProblemTurnProof --duration 60 <ingest.json>` â†’ `brief.json`
* `script --budget 110 <brief.json>` â†’ `vo.json`
* `plan <vo.json> <provenance.json>` â†’ `videoDoc.json`
* `lint <videoDoc.json>` â†’ nonâ€‘zero on failure
* `render --aspect 16:9,1:1,9:16 <videoDoc.json>`

**Acceptance**

* Each command exits nonâ€‘zero on failure with machineâ€‘readable errors.

---

## 8) Review Checklist for Existing Tool (Gap Analysis)

* [ ] Does the current system generate a **radioâ€‘first VO** and use cues to drive reveals?
* [ ] Are **shortâ€‘form budgets** enforced (word counts, scene caps)?
* [ ] Are **videoâ€‘first primitives** used (no app UI components)?
* [ ] Are **theme packs** decoupled from content JSON?
* [ ] Are **provenance tags** rendered inâ€‘frame and tied to VO cues?
* [ ] Do **lints** block renders and provide actionable fixes?
* [ ] Is **JSON Patch** diffing used for deterministic corrections?
* [ ] Multiâ€‘aspect rendering with safeâ€‘area discipline?
* [ ] Caching of TTS audio and assets by content hash?

---

## 9) Rollout Plan (Phased)

**Phase 1 â€” Foundations**

* Implement VDS tokens, primitives, motion grammar, theme packs (1â€“2 to start).
* Add DSL + validators + JSON patching.
* Add lints (design + pacing + provenance).
* Map one **60s microâ€‘explainer** template; render in 16:9.

**Phase 2 â€” Shortâ€‘form & Multiâ€‘Aspect**

* Add 30s templates (T1â€“T5).
* Add 1:1 and 9:16 with safeâ€‘area tokens and caption rules.
* Clip extraction and ClipScore.

**Phase 3 â€” Ops & Polish**

* Telemetry dashboard; cache; batch rendering queue.
* Additional theme packs; animation polish (camera drift, parallax, mask wipes).
* Optional: lightweight web reviewer for apply/preview JSON patches.

---

## 10) Risks & Mitigations

* **VO alignment drift:** TTS timestamps may vary across providers â†’ cache audio, pin engine/version, allow Â±120ms nudge.
* **Theme overfitting:** One theme fits all poorly â†’ enforce theme packs; allow perâ€‘scene accent override only.
* **Evidence gaps:** Missing provenance â†’ downgrade claims or block render; provide editor hints.

---

## 11) Open Questions (for Agent to resolve)

1. Which TTS engine/version will be standardized for deterministic cues?
2. Do we need multilingual captions/VO in v1?
3. Are there licensed brand fonts, or must we default to openâ€‘source variable families?
4. Who owns the provenance sources and link hygiene?
5. Required export codecs/bitrates per channel (YouTube, LinkedIn, TikTok)?

---

## 12) Acceptance Test Matrix (Representative)

| ID    | Scenario                    | Input                                 | Expected                                                                  |
| ----- | --------------------------- | ------------------------------------- | ------------------------------------------------------------------------- |
| ATâ€‘01 | 60s microâ€‘explainer renders | Whitepaper + brand tokens             | VideoDoc passes lints; 3 aspect outputs; provenance visible on stat scene |
| ATâ€‘02 | Overâ€‘budget VO              | 180 words for 60s                     | Build fails with budget error; suggests deletions                         |
| ATâ€‘03 | 30s clip extraction         | 45â€‘min podcast transcript             | Topâ€‘5 clips (24â€“33s); chosen template populated; captions present         |
| ATâ€‘04 | Missing provenance          | VO includes `[prov:s1]` not in ledger | Lint failure with pointer to scene/cue                                    |
| ATâ€‘05 | Patch determinism           | Apply + revert JSON patch             | Hash of outputs equals baseline                                           |
| ATâ€‘06 | Safeâ€‘area guard             | 9:16 render with long caption         | Caption reflows; no collision; contrast AA                                |

---

## 13) Appendices

### A) Shortâ€‘Form Budgets & Lints (machineâ€‘readable)

```json
{
  "budgets": {
    "clip30": { "wordsMax": 55, "sceneMaxSec": 20, "animConcurrentMax": 3 },
    "micro60": { "wordsMax": 110, "sceneMaxSec": 28, "animConcurrentMax": 3 },
    "micro75": { "wordsMax": 130, "sceneMaxSec": 28, "animConcurrentMax": 3 },
    "micro90": { "wordsMax": 160, "sceneMaxSec": 28, "animConcurrentMax": 3 }
  },
  "lints": {
    "narrative": ["hook", "turnBy40Pct", "ctaOrTakeaway"],
    "design": ["contrastAA", "safeAreas", "accentPerScene<=1", "concurrentAnims<=3"],
    "evidence": ["provTagForEveryProvToken"],
    "captions": ["max2Lines", "max32CharsPerLine", "noLowerThirdCollision"]
  }
}
```

### B) Example VideoDoc (60s Microâ€‘Explainer)

```json
{
  "story": {
    "controllingIdea": "Route by impact to turn noise into measurable wins.",
    "arc": "ProblemTurnProof",
    "targetDurationSec": 60,
    "audience": "exec",
    "allowResequence": true,
    "provenance": [
      {"id":"s1","label":"Ops Benchmarks 2024"},
      {"id":"s2","label":"Case: MidCo"}
    ]
  },
  "scenes": [
    {
      "id":"hook",
      "role":"HOOK",
      "voiceover":{"text":"Youâ€™re not short on data. Youâ€™re short on signal.","cues":[0]},
      "visuals":[{"kind":"TEXT","role":"title","text":"From data to signal"}],
      "durationMs":6000
    },
    {
      "id":"problem",
      "role":"PROBLEM",
      "voiceover":{"text":"Teams chase alerts. The expensive issues slip through. Last year, major incidents took weeks and six figures. [prov:s1]","cues":[0,2300,4700]},
      "visuals":[
        {"kind":"CHART","chart":"bar","data":{"labels":["Minor","Major"],"values":[12,96]},"emphasize":[1]},
        {"kind":"TEXT","role":"caption","text":"Ops Benchmarks 2024"}
      ],
      "evidence":[{"provId":"s1","atCue":2}]
    },
    {
      "id":"turn",
      "role":"TURN",
      "voiceover":{"text":"The turn is simple: score impact first, then spend time.","cues":[0]},
      "visuals":[{"kind":"SHAPE","shape":"bar","animate":"wipe"}]
    },
    {
      "id":"process",
      "role":"PROCESS",
      "voiceover":{"text":"Hereâ€™s how: one, quantify risk in dollars. Two, route by impact. Three, prove savings.","cues":[0,2100,4300]},
      "visuals":[
        {"kind":"CALLOUT","text":"$â€‘risk"},
        {"kind":"CALLOUT","text":"Impact routing"},
        {"kind":"CALLOUT","text":"Proof of savings"}
      ]
    },
    {
      "id":"proof",
      "role":"PROOF",
      "voiceover":{"text":"MidCo cut resolve time by thirty percent in one quarter. [prov:s2]","cues":[0]},
      "visuals":[
        {"kind":"CHART","chart":"metric","data":{"label":"TTR","value":"âˆ’30%"}},
        {"kind":"TEXT","role":"caption","text":"Case: MidCo"}
      ],
      "evidence":[{"provId":"s2","atCue":0}]
    },
    {
      "id":"cta",
      "role":"CTA",
      "voiceover":{"text":"See where your time pays off. Take the twoâ€‘minute assessment.","cues":[0]},
      "visuals":[
        {"kind":"TEXT","role":"title","text":"Start the 2â€‘minute assessment"},
        {"kind":"TEXT","role":"caption","text":"example.com/assessment"}
      ]
    }
  ]
}
```

### C) ESLint/TS Guidelines (for any new code)

* **TypeScript strict mode** on; no `any` in exported types.
* **No implicit `any`**, **no unused vars**, **no default export** for schema modules.
* Enforce Prettier defaults; ensure **named exports** for primitives and theme packs.

### D) Prompt Scaffolds (LLM)

1. **Narrative Brief** â†’ compact JSON with controlling idea, proof pillars (â‰¤3), arc.
2. **VO Script** â†’ split into scenes, mark sentence boundaries with `|`, include `[prov:id]`.
3. **Visual Mapping** â†’ assign primitives, ensure reveals at `cues`, limit concurrent animations.
4. **Fixes** â†’ always return RFC 6902 JSON patches targeting `VideoDoc`.

---

## 14) Definition of Done (DoD)

* **Functionally complete:** All FRs in Â§5 implemented; templates render in three aspects; lints block bad outputs.
* **Quality gates:** 10â€‘item acceptance matrix passes; automated tests for schema validation and lint checks.
* **Docs:** README for CLI; schema reference; examples for microâ€‘explainer and 30s clip.
* **Ops:** Telemetry dashboard shows job status; cache in place; reproducible renders.

---

### Final Note for the Agent

Start with **Phase 1 foundations** (VDS, DSL, motion grammar, lints, one 60s template). Ensure **VOâ€‘led** timing drives all reveals. Build JSONâ€‘patch corrections early to keep iteration cheap. Then add **30s clip extraction** and multiâ€‘aspect outputs.

If you want me to tailor this PRD to your current repo (file layout, modules, and specific gaps), share the existing structure and Iâ€™ll produce a targeted delta plan with precise refactors and task breakdown.
